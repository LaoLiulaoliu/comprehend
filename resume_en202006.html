<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Yuande Liu's resume</title>
  <meta name="keywords" content="Yuande Liu, resume">
  <meta name="description" content="Yuande Liu's resume">
  
  <style type="text/css">
  body {
    color: #222;
    background-color: #f9f9f9;
    width: 800px;
    margin: 0px auto;
  }
  ul, li, h4 {
    padding: 0px;
    margin: 0px;
  }
  li {
    list-style-type: none;
    list-style-position: inside;
  }
  li.list {
    list-style-type: circle;
    padding: 1px 0px;
  }
  h3 {
    color: rgb(51,88,238);
    background-color: #ededed;
    padding: 5px;
  }
  h4 {
    display: inline-block;
  }

  #header .header-title {
    text-align: center;
    padding: 10px 0px;
  }

  #content ul .info {
    display: inline-block;
    width: 48%;

  }
  #content .ul {
    padding: 10px 30px;
  }
  #content .ul .skill {
    list-style-type: lower-greek;
    padding: 1px 10px;
    list-style-position: outside;
  }

  #content .project {
    border-bottom: 1px solid rgba(229,229,229,0.4);
    padding: 20px 20px 10px;
  }
  #content .project .period {
    color: rgb(153, 153, 153);
    padding: 0px 10px;
  }
  #content .project dt {
    color: #757575;
  }
  #content .project dd {
    color: #3a3a3a;
    padding: 1px 0px;
    font-size: 14px;
  }
  </style>
</head>


<body>
<div id="header">
  <h2 class="header-title">Jameson Liu's resume</h2>
</div>

<div id="content">

  <div class="personal">
    <h3 class="title">Personal information</h3>
    <ul class="ul">
      <li class="info">Name：&nbsp;&nbsp;&nbsp;&nbsp;Jameson Yuande Liu</li>
      <li class="info">Sex：&nbsp;&nbsp;&nbsp;&nbsp;Male</li>
      <li class="info">Birth：&nbsp;&nbsp;&nbsp;&nbsp;March 17, 1987</li>
      <li class="info">Hometown：&nbsp;&nbsp;&nbsp;&nbsp;Xi'an</li>
      <li class="info">English skill：&nbsp;&nbsp;&nbsp;&nbsp;CET4</li>
      <li class="info">Reading：&nbsp;&nbsp;&nbsp;&nbsp;<a target="_blank" href="http://book.douban.com/people/3173950">http://book.douban.com/people/3173950</a></li>
      <li class="info">Cellphone：&nbsp;&nbsp;&nbsp;&nbsp;18392367623</li>
      <li class="info">Github:&nbsp;&nbsp;&nbsp;&nbsp;<a target="_blank" href="https://github.com/LaoLiulaoliu">https://github.com/LaoLiulaoliu</a></li>
      <li class="info">Email:&nbsp;&nbsp;&nbsp;&nbsp;<a href="mailto:miraclecome@gmail.com?subject=Dear Yuande">miraclecome@gmail.com</a></li>
      <li class="info">Kaggle:&nbsp;&nbsp;&nbsp;<a target="_blank" href="https://www.kaggle.com/laoliulaoliu">https://www.kaggle.com/laoliulaoliu</a></li>
    </ul>

    <h3 class="title">Self evaluation</h3>
    <ul class="ul">
        <li class="">☆ Participated in architecture work of various products in recent 5 years. Design technical functions of products from the prespective of business and users </li>
        <li class="">☆ Good at communication, good at innovation, strong logical thinking, team player, problem solver in global perspective. </li>
        <li class="">☆ Participate product development from conception to launch 4 times in two startups. Managed 3 small teams, interviewed 50+ people</li>
        <li class="">☆ Love algorithm. One of the organizers of Xi'an Tensorflow user group</li>
        <li class="">☆ Curious about the world, enjoy reading, thinking. In depth research on psychology, Buddhism and traditional Chinese medicine</li>
    </ul>

    <h3 class="title">Programming skill</h3>
    <ul class="ul">
      <li class="skill">Language: Python, Java, Gcc/G++, Shell/sed/awk, nodejs, html+css+JS/Jquery, Ruby, C#</li>
      <li class="skill">Database: Postgresql/Mysql, sharding MongoDB, sharding Redis</li>
      <li class="skill">Architecture: Amazon ecs/eks, Amazon lambda serverless</li>
      <li class="skill">BigData: Hadoop/Hbase, Spark, ELK, Cassandra</li>
      <li class="skill">Web: Spring+mybatis, Django, Tornado, Ruby on Rails, RESTful API</li>
      <li class="skill">Machine learning: CNN,RNN,transfer learning,semantic segmentation,classification(knn, decision tree, logistic regression, Naive Bayes), clustering(kmeans), regression(linear regression), Recommendation system(CF,SVD), feature engineering <a target="_blank" href="https://github.com/LaoLiulaoliu/MachineLearning">[code]</a></li>
      <li class="skill">Crawler: Distributed, high concurrent, scalable, easily monitored framework</li>
      <li class="skill">Devops: Jenkins, Terraform, Ansible</li>
      <li class="skill">OS: 14 years developing under Unix/Linux</li>
      <li class="skill">Network: TCP/IP, Network security(libnids/libnet, Deep packet inspection, Bypass DNS cheating, Email Bomb, ARP Cheating)</li>
      <li class="skill">Strategy: Optimize business strategy, iterate product system and user experience, agile methodology, design product to record user behavior and feedback</li>
    </ul>

    <h3 class="title">Partial project experience</h3>
    <ul class="ul">
      <li>
        <div class="project">
          <h4>Project at HSBC</h4><span class="period">( 2017.09 ~ 2019.10 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Macbook, Github, AWS, Mongodb, Cassandra, Hbase, Java, Python, Nodejs</dd>
            <dt>projects</dt>
            <dd>1. Big data storage and search based on user access behavior. Flume read log, parse and store to Hbase, Hive create external table, incrementally read Hbase and store it to Elasticsearch. Flume read log and save to mongodb, write parser in Java, converting user query from Elasticsearch to mongdb.</dd>
            <dd>2. Business loan application architecture on AWS cloud, bank level security and stability architecture, with large capacity and scalable. Terraform deployment architecture. CloudFront+APIGateway+Cognito+Lambda+Aurora+DynamoDB+CloudWatch+KMS+VPC</dd>
            <dd>3. Mulesoft, automation tool to convert the data from copybook to message specification, json doc, dwl file and test case. Finish normal project demands, to convert the message from frontend to backend and back.</dd>
            <dd>4. Use 20% study time to do image classification with ensemble of ResNet and DenseNet, learn SSD, FCN, style transfer, RNN and textCNN </dd>
          </dl>
        </div>
      </li>
      <li>
        <div class="project">
          <h4>Crawler Framework</h4><span class="period">( 2016.05 ~ 2016.06 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Ubuntu, Git, Vim, Postgresql, Redis, Django, Python(requests+lxml+cssselect), Fabric, Supervisor</dd>
            <dt>crawl haodaifu.com</dt>
            <dd>1. Website will block IP who access too frequently. I wanted to buy Amazon ec2 or IP proxy, but my boss did not give me any budget, so I found free proxy. Checking useful anonymous proxy, use gevent to solve checking slow problem.</dd>
            <dd>2. python psycopg2 accessing DB is trivial, ORM performances is bad, I wrote a mongodb-like query module -- pgwrapper，submit to pypi</dd>
            <dt>Python crawl wanfang medical literature data</dt>
            <dd>1. Crack login captcha with PIL, easy number captcha just crop and compare the subimage, hard captcha have spots, adjoined jagged edge characters, use binarization, drop light gray spots, drop isolated spots, distinguish edge by gray difference</dd>
            <dd>2. Distributed crawler, every work get tasks from redis, mark the finished one, requeue unfinished one. enqueue, dequeue, requeue, use 3 concurrent gevent coroutine</dd>
            <dd>3. Extracting author Email of PDF, give feedback about pdfminer bug</dd>
            <dd>4. Print, taceback, review source code, read log, pdb for debugging, parallel and concurrent program need more temporary log for debugging</dd>
            <dt>Python crawl CFDA drugs</dt>
            <dd>Django build a private management backend for unified drug metering</dd>
          </dl>
      </li>
      <li>
        <div class="project">
          <h4>Patient management and service system</h4><span class="period">( 2015.06 ~ 2015.12 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Debian, Git, IntelliJ IDEA, Java+Spring+Mybatis, iPython+Jupyter+Numpy+Pandas+Seaborn+Scikit-learn</dd>
            <dt>Duty</dt>
            <dd>Based on business logic, draw network topology diagram, program architecture diagram</dd>
            <dd>In charge of join in Hospital Information System, provide data acquisition solution</dd>
            <dd>Research on cleansing and mining, using kmeans to cluster different patients. The data have too many dimentions and very sparse, need medical support.</dd>
          </dl>
        </div>
      </li>
      <li>
        <div class="project">
          <h4>Ourdrs website backend and data</h4><span class="period">( 2014.07 ~ 2014.12 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Mac(development)/Aliyun ubuntu(production), Qiniu Yun, Git, Vim, Ruby on Rails, Postgresql, Redis, ElasticSearch</dd>
            <dt>Description</dt>
            <dd>Arrange business and product logic of doctor patient interation, develop and improve website <a target=_blank href="https://ourdrs.com">https://ourdrs.com</a> </dd>
            <dt>Duty</dt>
            <dd>1. Build website based on business and product logic.</dd>
            <dd>2. DevOps, security problem prevention</dd>
            <dd>3. Backend RESTful API, Ruby on Rails+grape+swagger+qiniu+smart_sms+websocket+redis+capistrano+newrelic+unicorn+factory_girl+faker+pundit <a target=_blank href="https://github.com/LaoLiulaoliu/speech">ROR problem we met</a> </dd>
            <dd>4. FactoryGirl+Rspec for unit test and forging data</dd>
            <dd>5. Besides tongji.baidu.com, I build a same period group model for testing user behavior of our site. Using D3js to draw the pretty diagram.</dd>
          </dl>
        </div>
      </li>
      <li>
        <div class="project">
          <h4>Data007 Taobao shop data analysis</h4><span class="period">( 2014.01 ~ 2014.05 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Mac(development)/Amazon ec2 ubuntu(production), Git, Vim, Python2.7, virtualenv, Redis, Cassandra</dd>
            <dt>Description</dt>
            <dd>crawl taobao, tmall data, doing statistics and show</dd>
            <dt>Duty</dt>
            <dd>1. Based on open taobao API get all the categories we want.Two pipeline redis queue, one for shop info, the other for item info in the shop, requeue failed one. Save info to cassandra</dd>
            <dd>2. Crawling mobile h5 page of taobao is still slow, found data in RESTful API without limiation, JsV8 engine to resolve js format data.</dd>
            <dd>3. Reduce the crawl frequence exponentially for products and shops with no sale, cassandra is slow, so I put this strategy in redis with bit format data</dd>
            <dd>4. Use hash_ring to realize a distributed redis, multiple similar commands use pipline of redis</dd>
            <dd>5. Dynamically shutdown and power on Amazon ec2 as a crawler worker, avoid been blocked by taobao. Also use throttling to limit the rate of crawling taobao </dd>
            <dd>6. Cassandra configuration, nodetool monitor, Hadoop/Hbase configuration, installation, usage</dd>
          </dl>
        </div>
      </li>
      <li>
        <div class="project">
          <h4>Favbuy overseas sale</h4><span class="period">( 2012.08 ~ 2014.05 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Ubuntu(development)/Amazon ec2 ubuntu(production), Git, Vim, Python2.7, virtualenv, mongodb, Redis, selenium</dd>
            <dt>Description</dt>
            <dd>Crawl Myhabit, Gilt, Ruelala, Amazon, Bestbuy... , extracting, classify, aggregation, display on the web</dd>
            <dt>Duty</dt>
            <dd>1. Use requests+lxml, selenium, RESTful API to crawl more than 30 electronic commerce website</dd>
            <dd>2. Assure the accuracy of data, build crawler data report and everyday new products report, find crawler bug or website update page framework</dd>
            <dd>3. Crawlers as RPC server in 4 servers, RPC client manage crawlers running, both server and client message send to redis for processing</dd>
            <dd>4. Deploy on Amazon EC2, monitor by Ganglia, guarantee all the server normal running, problem automatically sending by skype</dd>
            <dd>5. Open file handler too many, modify ulimit in deploy code, later find rpc client open too many</dd>
            <dd>6. Django unit test, RESTful API unit test</dd>
            <dd>7. Recording user behavior of browse, love, buy, share, give them a weighted based on experience, calculating the fancy degree. Operation guy give goods different tags in backend, calculate the similarity of every two goods every two hours, save in redis. Calculate most related goods of top10 fancy goods when user access homepage, cache the recommendation.</dd>
            <dd>Improvement: recommand related goods of all the fancy goods, not just top10, record which recommanded goods that user clicked, use logistic regression calculate the weighted of different user behaviors.</dd>
          </dl>
        </div>
      </li>
      <li>
        <div class="project">
          <h4>Simple search engine</h4><span class="period">( 2012.02 ~ 2012.03 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>Debian, Github, Vim, Python3</dd>
            <dt>Description</dt>
            <dd>1. Using python pseudo thread pool, crawl 9 deepth of webpage from seed pages, new page enqueue</dd>
            <dd>2. stemming word on webpage, inverted word indexing, calculate page rank based on url and outgoing url</dd>
            <dd>3. dump data to disk, caching the search, sort search result based on rank*TF-IDF, search continuous words</dd>
            <dt>Duty</dt>
            <dd>all the coding</dd>
          </dl>
        </div>
      </li>
      <li>
        <div class="project">
          <h4>protocol recognition and block</h4><span class="period">( 2011.04 ~ 2011.06 )</span>
          <dl>
            <dt>Environment</dt>
            <dd>RedHat, Svn, Vim, C++(G++), L7-filter</dd>
            <dt>Description</dt>
            <dd>1. Packet between Internet and Intranet, Recognise the protocol, poison specified DNS query</dd>
            <dd>2. Modify regular expression of L7-filter, precisely match specific protocol</dd>
            <dd>3. Re-development RRDtool, generate statistical image of dozens of protocols</dd>
            <dd>4. Modify hash function, add semaphore between two process, improve program performance and speed</dd>
            <dt>Duty</dt>
            <dd>all the c++ coding</dd>
          </dl>
        </div>
      </li>
    </ul>

    <h3 class="title">Education</h3>
    <ul class="ul">
      <li class="list">2019-01 – 2019-05   Deep learning online class</li>
      <li class="list">2012-02 – 2012-04   Udacity: Build a search engine, robotic car(highest distinction)</li>
      <li class="list">2011-10 – 2011-12   Stanford University On-line class(AI(81.6%), Machine Learning)</li>
      <li class="list">2005-09 – 2010-01   Nanjing University of Posts and Telecommunications, Information Security Bachelor</li>
    </ul>

    <h3 class="title">Working experience</h3>
    <ul class="ul">
      <li class="list">2017-09 – 2019-11   Chinasoft international, Project manager, AWS microservice architecture, big data, Mulesoft API</li>
      <li class="list">2016-03 – 2017-02   Haizhi Intelligent(Shanghai) Co. Ltd.  Distributed Crawler Framework, Knowledge graph design, ELK, docker, Operation Management</li>
      <li class="list">2014-07 – 2015-12   Hejie Health Consultation Co. Ltd.  Data processing and Machine learning</li>
      <li class="list">2012-04 – 2014-06   Favbuy(Shanghai) corporation  Distributed crawler, Web, DevOps, Data processing</li>
      <li class="list">2010-01 – 2011-12   Nanjing Fenghuo Communication Development Co. Ltd. Network Security Research and Development</li>
    </ul>

  </div>
</div>

<div id="footer">
</div>

</body>
</html>
