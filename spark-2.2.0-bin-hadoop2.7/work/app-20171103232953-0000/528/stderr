17/11/03 23:39:09 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 29643@lyc-laptop
17/11/03 23:39:09 INFO util.SignalUtils: Registered signal handler for TERM
17/11/03 23:39:09 INFO util.SignalUtils: Registered signal handler for HUP
17/11/03 23:39:09 INFO util.SignalUtils: Registered signal handler for INT
17/11/03 23:39:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/11/03 23:39:10 INFO spark.SecurityManager: Changing view acls to: lyc
17/11/03 23:39:10 INFO spark.SecurityManager: Changing modify acls to: lyc
17/11/03 23:39:10 INFO spark.SecurityManager: Changing view acls groups to: 
17/11/03 23:39:10 INFO spark.SecurityManager: Changing modify acls groups to: 
17/11/03 23:39:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lyc); groups with view permissions: Set(); users  with modify permissions: Set(lyc); groups with modify permissions: Set()
17/11/03 23:39:10 INFO client.TransportClientFactory: Successfully created connection to /192.168.2.200:44215 after 58 ms (0 ms spent in bootstraps)
17/11/03 23:39:10 INFO spark.SecurityManager: Changing view acls to: lyc
17/11/03 23:39:10 INFO spark.SecurityManager: Changing modify acls to: lyc
17/11/03 23:39:10 INFO spark.SecurityManager: Changing view acls groups to: 
17/11/03 23:39:10 INFO spark.SecurityManager: Changing modify acls groups to: 
17/11/03 23:39:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lyc); groups with view permissions: Set(); users  with modify permissions: Set(lyc); groups with modify permissions: Set()
17/11/03 23:39:10 INFO client.TransportClientFactory: Successfully created connection to /192.168.2.200:44215 after 0 ms (0 ms spent in bootstraps)
Exception in thread "main" java.lang.IllegalArgumentException: System memory 419430400 must be at least 471859200. Please increase heap size using the --driver-memory option or spark.driver.memory in Spark configuration.
	at org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:217)
	at org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:199)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:332)
	at org.apache.spark.SparkEnv$.createExecutorEnv(SparkEnv.scala:201)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1.apply$mcV$sp(CoarseGrainedExecutorBackend.scala:223)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:67)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:66)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:66)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:188)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:284)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)
